<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Implementation Details · Effort.jl</title><meta name="title" content="Implementation Details · Effort.jl"/><meta property="og:title" content="Implementation Details · Effort.jl"/><meta property="twitter:title" content="Implementation Details · Effort.jl"/><meta name="description" content="Documentation for Effort.jl."/><meta property="og:description" content="Documentation for Effort.jl."/><meta property="twitter:description" content="Documentation for Effort.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.svg" alt="Effort.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="Effort.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../example/">Example</a></li><li class="is-active"><a class="tocitem" href>Implementation Details</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#1.-Background-Cosmology-and-Growth-Factors"><span>1. Background Cosmology and Growth Factors</span></a></li><li><a class="tocitem" href="#2.-Power-Spectrum-Emulation"><span>2. Power Spectrum Emulation</span></a></li><li><a class="tocitem" href="#3.-Alcock-Paczynski-Effect"><span>3. Alcock-Paczynski Effect</span></a></li><li><a class="tocitem" href="#4.-Interpolation:-Akima-Splines"><span>4. Interpolation: Akima Splines</span></a></li><li><a class="tocitem" href="#5.-Window-Convolution"><span>5. Window Convolution</span></a></li><li><a class="tocitem" href="#6.-Differentiation:-Automatic-vs-Analytical"><span>6. Differentiation: Automatic vs Analytical</span></a></li><li><a class="tocitem" href="#7.-Performance-Optimizations"><span>7. Performance Optimizations</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li><li><a class="tocitem" href="#Further-Reading"><span>Further Reading</span></a></li></ul></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../api_external/">External API</a></li><li><a class="tocitem" href="../api_internal/">Internal API</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Implementation Details</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Implementation Details</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/CosmologicalEmulators/Effort.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/CosmologicalEmulators/Effort.jl/blob/main/docs/src/implementation_details.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Implementation-Details"><a class="docs-heading-anchor" href="#Implementation-Details">Implementation Details</a><a id="Implementation-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-Details" title="Permalink"></a></h1><p>This page provides technical details about the algorithms and numerical methods implemented in <code>Effort.jl</code>.</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>The package implements efficient computational methods for:</p><ol><li><strong>Background cosmology</strong> - ODE solvers for growth factors</li><li><strong>Neural network emulation</strong> - Fast prediction of power spectrum multipoles</li><li><strong>Alcock-Paczynski corrections</strong> - Geometric distortions from cosmological parameters</li><li><strong>Window convolution</strong> - Survey geometry effects</li></ol><hr/><h2 id="1.-Background-Cosmology-and-Growth-Factors"><a class="docs-heading-anchor" href="#1.-Background-Cosmology-and-Growth-Factors">1. Background Cosmology and Growth Factors</a><a id="1.-Background-Cosmology-and-Growth-Factors-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Background-Cosmology-and-Growth-Factors" title="Permalink"></a></h2><h3 id="Normalized-Hubble-Parameter"><a class="docs-heading-anchor" href="#Normalized-Hubble-Parameter">Normalized Hubble Parameter</a><a id="Normalized-Hubble-Parameter-1"></a><a class="docs-heading-anchor-permalink" href="#Normalized-Hubble-Parameter" title="Permalink"></a></h3><p>The normalized Hubble parameter <span>$E(z)$</span> quantifies the expansion rate of the universe as a function of redshift:</p><p class="math-container">\[E(z) = \frac{H(z)}{H_0} = \sqrt{\Omega_m(1+z)^3 + \Omega_k(1+z)^2 + \Omega_{DE}(z)}\]</p><p>For the w0waCDM model, the dark energy density parameter evolves as:</p><p class="math-container">\[\Omega_{DE}(z) = \Omega_{DE,0} (1+z)^{3(1 + w_0 + w_a)} \exp\left(-\frac{3w_a z}{1+z}\right)\]</p><h3 id="Growth-Factor-D(z)"><a class="docs-heading-anchor" href="#Growth-Factor-D(z)">Growth Factor D(z)</a><a id="Growth-Factor-D(z)-1"></a><a class="docs-heading-anchor-permalink" href="#Growth-Factor-D(z)" title="Permalink"></a></h3><p>The linear growth factor <span>$D(z)$</span> describes the growth of matter perturbations and is computed by solving the ODE:</p><p class="math-container">\[\frac{d^2 D}{da^2} + \left(\frac{3}{a} + \frac{d\ln H}{da}\right)\frac{dD}{da} = \frac{3\Omega_m(a)}{2a^2} D\]</p><p>where <span>$a = 1/(1+z)$</span> is the scale factor. This is solved using high-order Runge-Kutta methods (Tsit5) from <code>OrdinaryDiffEq.jl</code>.</p><p><strong>Initial conditions</strong>: At high redshift (<span>$z = 1000$</span>), the growth factor is normalized such that <span>$D(z=0) = 1$</span> in the fiducial cosmology.</p><h3 id="Growth-Rate-f(z)"><a class="docs-heading-anchor" href="#Growth-Rate-f(z)">Growth Rate f(z)</a><a id="Growth-Rate-f(z)-1"></a><a class="docs-heading-anchor-permalink" href="#Growth-Rate-f(z)" title="Permalink"></a></h3><p>The logarithmic derivative of the growth factor is the growth rate:</p><p class="math-container">\[f(z) = \frac{d \ln D}{d \ln a} = -(1+z) \frac{dD/dz}{D}\]</p><p>This parameter appears in redshift-space distortions and affects the quadrupole and hexadecapole multipoles.</p><hr/><h2 id="2.-Power-Spectrum-Emulation"><a class="docs-heading-anchor" href="#2.-Power-Spectrum-Emulation">2. Power Spectrum Emulation</a><a id="2.-Power-Spectrum-Emulation-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Power-Spectrum-Emulation" title="Permalink"></a></h2><h3 id="Neural-Network-Architecture"><a class="docs-heading-anchor" href="#Neural-Network-Architecture">Neural Network Architecture</a><a id="Neural-Network-Architecture-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Network-Architecture" title="Permalink"></a></h3><p>The emulators use feedforward neural networks to predict power spectrum components:</p><ul><li><strong>Input</strong>: 9 cosmological parameters <span>$\{z, \ln(10^{10}A_{\mathrm{s}}), n_{\mathrm{s}}, H_0, \omega_b, \omega_{\mathrm{cdm}}, \Sigma m_\nu, w_0, w_a\}$</span></li><li><strong>Hidden layers</strong>: Multiple hidden layers with activation functions</li><li><strong>Output</strong>: Three components of the power spectrum:<ul><li><span>$P_{11}$</span>: Linear-linear contribution</li><li><span>$P_{\text{loop}}$</span>: One-loop contribution</li><li><span>$P_{ct}$</span>: Counter-term contribution</li></ul></li></ul><h3 id="Bias-Expansion"><a class="docs-heading-anchor" href="#Bias-Expansion">Bias Expansion</a><a id="Bias-Expansion-1"></a><a class="docs-heading-anchor-permalink" href="#Bias-Expansion" title="Permalink"></a></h3><p>The observed galaxy power spectrum is related to the matter power spectrum through bias parameters <span>$b_i$</span>:</p><p class="math-container">\[P_g(k, \mu) = D^2 \sum_{i=1}^{N_{\text{bias}}} b_i \cdot \mathcal{B}_i(k, \mu; P_{11}, P_{\text{loop}}, P_{ct})\]</p><p>where <span>$\mathcal{B}_i$</span> are basis functions combining the emulated components with geometric factors.</p><p><strong>Standard setup</strong>: 11 bias parameters, including:</p><ul><li><span>$b_1$</span>: Linear bias</li><li><span>$b_2, b_3, \ldots$</span>: Higher-order bias terms</li><li><span>$b_8 = f(z)$</span>: Growth rate (for RSD)</li><li><span>$b_9, b_{10}, b_{11}$</span>: Stochastic and shot noise terms</li></ul><hr/><h2 id="3.-Alcock-Paczynski-Effect"><a class="docs-heading-anchor" href="#3.-Alcock-Paczynski-Effect">3. Alcock-Paczynski Effect</a><a id="3.-Alcock-Paczynski-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Alcock-Paczynski-Effect" title="Permalink"></a></h2><h3 id="Physical-Interpretation"><a class="docs-heading-anchor" href="#Physical-Interpretation">Physical Interpretation</a><a id="Physical-Interpretation-1"></a><a class="docs-heading-anchor-permalink" href="#Physical-Interpretation" title="Permalink"></a></h3><p>The Alcock-Paczynski (AP) effect arises when the assumed reference cosmology differs from the true cosmology. Observations are made in redshift space <span>$(k_o, \mu_o)$</span>, but the true clustering is in real space <span>$(k_t, \mu_t)$</span>.</p><h3 id="AP-Parameters"><a class="docs-heading-anchor" href="#AP-Parameters">AP Parameters</a><a id="AP-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#AP-Parameters" title="Permalink"></a></h3><p>The distortion is quantified by two parameters:</p><p class="math-container">\[q_\parallel(z) = \frac{H_{\text{ref}}(z)}{H_{\text{true}}(z)} = \frac{E_{\text{ref}}(z)}{E_{\text{true}}(z)}\]</p><p class="math-container">\[q_\perp(z) = \frac{d_{A,\text{true}}(z)}{d_{A,\text{ref}}(z)} = \frac{\tilde{d}_{A,\text{true}}(z)}{\tilde{d}_{A,\text{ref}}(z)}\]</p><p>where <span>$d_A$</span> is the angular diameter distance and <span>$\tilde{d}_A$</span> is the conformal angular diameter distance.</p><p><strong>Physical meaning</strong>:</p><ul><li><span>$q_\parallel &lt; 1$</span>: Reference cosmology overestimates radial distances → clustering appears compressed along line-of-sight</li><li><span>$q_\perp &lt; 1$</span>: Reference cosmology overestimates transverse distances → clustering appears compressed perpendicular to line-of-sight</li></ul><h3 id="Coordinate-Transformation"><a class="docs-heading-anchor" href="#Coordinate-Transformation">Coordinate Transformation</a><a id="Coordinate-Transformation-1"></a><a class="docs-heading-anchor-permalink" href="#Coordinate-Transformation" title="Permalink"></a></h3><p>The transformation from observed to true coordinates:</p><p class="math-container">\[k_t = \frac{k_o}{q_\perp} \sqrt{1 + \mu_o^2 \left(\frac{q_\perp^2}{q_\parallel^2} - 1\right)}\]</p><p class="math-container">\[\mu_t = \frac{\mu_o q_\perp}{q_\parallel \sqrt{1 + \mu_o^2 \left(\frac{q_\perp^2}{q_\parallel^2} - 1\right)}}\]</p><h3 id="Observed-Power-Spectrum"><a class="docs-heading-anchor" href="#Observed-Power-Spectrum">Observed Power Spectrum</a><a id="Observed-Power-Spectrum-1"></a><a class="docs-heading-anchor-permalink" href="#Observed-Power-Spectrum" title="Permalink"></a></h3><p>The observed power spectrum in redshift space is:</p><p class="math-container">\[P_{\text{obs}}(k_o, \mu_o) = \frac{1}{q_\parallel q_\perp^2} P_{\text{true}}(k_t, \mu_t)\]</p><p>The factor <span>$1/(q_\parallel q_\perp^2)$</span> accounts for the volume distortion.</p><h3 id="Multipole-Projection"><a class="docs-heading-anchor" href="#Multipole-Projection">Multipole Projection</a><a id="Multipole-Projection-1"></a><a class="docs-heading-anchor-permalink" href="#Multipole-Projection" title="Permalink"></a></h3><p>To obtain the observed multipoles, we integrate over the angular dependence:</p><p class="math-container">\[P_\ell(k_o) = (2\ell + 1) \int_0^1 P_{\text{obs}}(k_o, \mu_o) \mathcal{L}_\ell(\mu_o) \, d\mu_o\]</p><p>where <span>$\mathcal{L}_\ell(\mu)$</span> are Legendre polynomials:</p><p class="math-container">\[\begin{aligned}
\mathcal{L}_0(\mu) &amp;= 1 \\
\mathcal{L}_2(\mu) &amp;= \frac{1}{2}(3\mu^2 - 1) \\
\mathcal{L}_4(\mu) &amp;= \frac{1}{8}(35\mu^4 - 30\mu^2 + 3)
\end{aligned}\]</p><h3 id="Numerical-Implementation"><a class="docs-heading-anchor" href="#Numerical-Implementation">Numerical Implementation</a><a id="Numerical-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Implementation" title="Permalink"></a></h3><p><code>Effort.jl</code> provides two implementations:</p><h4 id="1.-Standard-Implementation-(apply_AP)"><a class="docs-heading-anchor" href="#1.-Standard-Implementation-(apply_AP)">1. Standard Implementation (<code>apply_AP</code>)</a><a id="1.-Standard-Implementation-(apply_AP)-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Standard-Implementation-(apply_AP)" title="Permalink"></a></h4><p>Uses <strong>Gauss-Lobatto quadrature</strong> for fast integration:</p><ol><li>Compute quadrature nodes <span>$\mu_1, \ldots, \mu_n$</span> and weights <span>$w_1, \ldots, w_n$</span></li><li>For each <span>$k_o$</span> and each <span>$\mu_i$</span>:<ul><li>Transform to true coordinates: <span>$(k_t, \mu_t) = f(k_o, \mu_i; q_\parallel, q_\perp)$</span></li><li>Interpolate true multipoles at <span>$k_t$</span> using Akima splines</li><li>Reconstruct <span>$P_{\text{true}}(k_t, \mu_t)$</span> from multipoles</li><li>Scale by volume factor: <span>$P_{\text{obs}} = P_{\text{true}} / (q_\parallel q_\perp^2)$</span></li></ul></li><li>Compute weighted sum: <span>$P_\ell(k_o) = (2\ell+1) \sum_i w_i P_{\text{obs}}(k_o, \mu_i) \mathcal{L}_\ell(\mu_i)$</span></li></ol><p><strong>Typical performance</strong>: ~30 μs for 3 multipoles at 50 k-points (8 Gauss-Lobatto nodes)</p><p><strong>Exploiting symmetry</strong>: Since the integrand is even in <span>$\mu$</span> for even multipoles (<span>$\ell = 0, 2, 4$</span>), we only integrate over <span>$[0, 1]$</span> instead of <span>$[-1, 1]$</span>, halving the number of evaluations.</p><h4 id="2.-Check-Implementation-(apply_AP_check)"><a class="docs-heading-anchor" href="#2.-Check-Implementation-(apply_AP_check)">2. Check Implementation (<code>apply_AP_check</code>)</a><a id="2.-Check-Implementation-(apply_AP_check)-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Check-Implementation-(apply_AP_check)" title="Permalink"></a></h4><p>Uses adaptive quadrature (QuadGK) for validation:</p><ul><li>Higher accuracy (<span>$\text{reltol} = 10^{-12}$</span>)</li><li>~10-100× slower than Gauss-Lobatto</li><li>Useful for testing and verification</li></ul><hr/><h2 id="4.-Interpolation:-Akima-Splines"><a class="docs-heading-anchor" href="#4.-Interpolation:-Akima-Splines">4. Interpolation: Akima Splines</a><a id="4.-Interpolation:-Akima-Splines-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Interpolation:-Akima-Splines" title="Permalink"></a></h2><p>Multipole moments are defined on a discrete k-grid, but AP corrections require evaluation at arbitrary <span>$k_t$</span> values. <code>Effort.jl</code> uses <strong>Akima interpolation</strong> for this purpose.</p><h3 id="Why-Akima?"><a class="docs-heading-anchor" href="#Why-Akima?">Why Akima?</a><a id="Why-Akima?-1"></a><a class="docs-heading-anchor-permalink" href="#Why-Akima?" title="Permalink"></a></h3><p>Compared to cubic splines:</p><ul><li><strong>Local</strong>: Each interval depends only on 5 nearby points (vs. global for cubic splines)</li><li><strong>No oscillations</strong>: Avoids Runge&#39;s phenomenon near steep gradients</li><li><strong>Fast</strong>: Efficient for repeated evaluations</li></ul><h3 id="Mathematical-Form"><a class="docs-heading-anchor" href="#Mathematical-Form">Mathematical Form</a><a id="Mathematical-Form-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Form" title="Permalink"></a></h3><p>For data points <span>$(k_1, P_1), \ldots, (k_n, P_n)$</span>, Akima constructs a piecewise cubic polynomial:</p><p class="math-container">\[P(k) = a_i + b_i(k - k_i) + c_i(k - k_i)^2 + d_i(k - k_i)^3, \quad k \in [k_i, k_{i+1}]\]</p><p>Coefficients are determined by local slopes that minimize oscillations.</p><p><strong>Extrapolation</strong>: Uses nearest-neighbor extension (constant extrapolation beyond data range).</p><hr/><h2 id="5.-Window-Convolution"><a class="docs-heading-anchor" href="#5.-Window-Convolution">5. Window Convolution</a><a id="5.-Window-Convolution-1"></a><a class="docs-heading-anchor-permalink" href="#5.-Window-Convolution" title="Permalink"></a></h2><p>Survey geometry introduces correlations between different <span>$k$</span> modes through the window function <span>$W(k, k&#39;)$</span>:</p><p class="math-container">\[P_{\ell}^{\text{obs}}(k) = \sum_{k&#39;} W_{\ell\ell&#39;}(k, k&#39;) P_{\ell&#39;}^{\text{true}}(k&#39;)\]</p><p>For 2D analyses (<span>$k$</span> and multipole <span>$\ell$</span>), this generalizes to a 4D kernel:</p><p class="math-container">\[C_{ik} = \sum_{jl} W_{ijkl} v_{jl}\]</p><p>This is efficiently computed using the <code>@tullio</code> macro for tensor contractions.</p><p><strong>Applications</strong>:</p><ul><li>Fiber collisions</li><li>Angular selection functions</li><li>Survey boundaries</li></ul><p><strong>Reference</strong>: <a href="https://arxiv.org/abs/1810.05051">Beutler et al. 2019 (arXiv:1810.05051)</a></p><hr/><h2 id="6.-Differentiation:-Automatic-vs-Analytical"><a class="docs-heading-anchor" href="#6.-Differentiation:-Automatic-vs-Analytical">6. Differentiation: Automatic vs Analytical</a><a id="6.-Differentiation:-Automatic-vs-Analytical-1"></a><a class="docs-heading-anchor-permalink" href="#6.-Differentiation:-Automatic-vs-Analytical" title="Permalink"></a></h2><p><code>Effort.jl</code> provides two complementary differentiation strategies, each optimized for specific use cases in cosmological inference.</p><h3 id="6.1-Automatic-Differentiation-(AD)"><a class="docs-heading-anchor" href="#6.1-Automatic-Differentiation-(AD)">6.1 Automatic Differentiation (AD)</a><a id="6.1-Automatic-Differentiation-(AD)-1"></a><a class="docs-heading-anchor-permalink" href="#6.1-Automatic-Differentiation-(AD)" title="Permalink"></a></h3><p>The package is fully compatible with Julia&#39;s AD ecosystem:</p><ul><li><strong>ForwardDiff.jl</strong>: Forward-mode AD for efficient gradients (explicitly tested)</li><li><strong>Zygote.jl</strong>: Reverse-mode AD for large parameter spaces (explicitly tested)</li></ul><p><strong>Use case</strong>: Gradient-based MCMC (HMC, NUTS) and maximum likelihood optimization.</p><p>When performing MCMC or variational inference, you can differentiate the likelihood function directly through the entire pipeline (ODE solvers → emulators → AP corrections). This works seamlessly because:</p><ul><li><strong>Custom ChainRules</strong>: Hand-written adjoints for Akima interpolation, window convolution, and other critical operations</li><li><strong>SciMLSensitivity</strong>: Efficient gradients through ODE solvers via sensitivity analysis</li><li><strong>Non-mutating code</strong>: All functions avoid in-place mutations (Zygote-compatible)</li></ul><p><strong>Example derivatives</strong>:</p><p class="math-container">\[\frac{\partial \mathcal{L}}{\partial \theta_i} \quad \text{where } \theta \in \{h, \omega_c, w_0, \ldots\}\]</p><h3 id="6.2-Analytical-Jacobians"><a class="docs-heading-anchor" href="#6.2-Analytical-Jacobians">6.2 Analytical Jacobians</a><a id="6.2-Analytical-Jacobians-1"></a><a class="docs-heading-anchor-permalink" href="#6.2-Analytical-Jacobians" title="Permalink"></a></h3><p>The package also provides <strong>analytical Jacobian implementations</strong> for derivatives with respect to bias parameters:</p><p class="math-container">\[J_{ki} = \frac{\partial P_\ell(k)}{\partial b_i}\]</p><p><strong>Use case</strong>: Fisher Information Matrix computation for Jeffreys priors and survey forecasts.</p><p><strong>Why not use AD?</strong> When computing Fisher matrices during MCMC analysis, using AD for Jacobians would require:</p><ol><li>Computing Jacobian via AD: <span>$J = \nabla_{b} P_\ell(k; b)$</span></li><li>Differentiating likelihood (which uses <span>$J$</span>) via AD: <span>$\nabla_{\theta} \mathcal{L}(\theta; J)$</span></li></ol><p>This is <strong>AD over AD</strong> (nested differentiation), which is:</p><ul><li>Computationally expensive</li><li>Numerically unstable</li><li>Difficult to debug</li></ul><p><strong>Solution</strong>: Analytical Jacobians avoid this by providing closed-form derivatives. These are:</p><ul><li><strong>Fast</strong>: Direct computation without AD overhead</li><li><strong>Memory-efficient</strong>: Optimized matrix operations</li><li><strong>Validated</strong>: Tested against both Computer Algebra Systems (symbolic differentiation) and AD (numerical validation)</li></ul><p>The validation ensures:</p><p class="math-container">\[J_{\text{analytical}} \approx J_{\text{AD}} \approx J_{\text{CAS}} \quad (\text{within numerical precision})\]</p><h3 id="6.3-Implementation-Details"><a class="docs-heading-anchor" href="#6.3-Implementation-Details">6.3 Implementation Details</a><a id="6.3-Implementation-Details-1"></a><a class="docs-heading-anchor-permalink" href="#6.3-Implementation-Details" title="Permalink"></a></h3><p><strong>AD-compatible operations</strong>:</p><ul><li>Neural network evaluation (matrix operations)</li><li>ODE solvers with SciMLSensitivity</li><li>Akima interpolation with custom ChainRules</li><li>Window convolution via <code>Tullio.jl</code> (AD-aware)</li></ul><p><strong>Analytical Jacobian features</strong>:</p><ul><li>Batched computation for all 11 bias parameters simultaneously</li><li>Matrix interface compatible with <code>apply_AP</code> for efficient AP corrections</li><li>Explicit tests in <code>test/test_pipeline.jl</code> validate against ForwardDiff, Zygote, and FiniteDifferences</li></ul><hr/><h2 id="7.-Performance-Optimizations"><a class="docs-heading-anchor" href="#7.-Performance-Optimizations">7. Performance Optimizations</a><a id="7.-Performance-Optimizations-1"></a><a class="docs-heading-anchor-permalink" href="#7.-Performance-Optimizations" title="Permalink"></a></h2><h3 id="Batch-Processing"><a class="docs-heading-anchor" href="#Batch-Processing">Batch Processing</a><a id="Batch-Processing-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-Processing" title="Permalink"></a></h3><p>The <code>apply_AP</code> function supports matrix inputs, allowing multiple columns (e.g., Jacobian columns) to be processed simultaneously:</p><pre><code class="language-julia hljs">apply_AP(k_in, k_out, mono_matrix, quad_matrix, hexa_matrix, q_par, q_perp)</code></pre><p><strong>Speedup</strong>: ~2.5× faster than column-by-column processing by using optimized matrix Akima interpolation.</p><h3 id="Memory-Efficiency"><a class="docs-heading-anchor" href="#Memory-Efficiency">Memory Efficiency</a><a id="Memory-Efficiency-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Efficiency" title="Permalink"></a></h3><ul><li>Preallocated arrays for intermediate computations</li><li>In-place operations where possible (avoiding allocations)</li><li>Broadcasting for vectorized operations</li></ul><h3 id="Numerical-Stability"><a class="docs-heading-anchor" href="#Numerical-Stability">Numerical Stability</a><a id="Numerical-Stability-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Stability" title="Permalink"></a></h3><ul><li>Logarithmic extrapolation for power spectra (prevents negative values)</li><li>Relative tolerances adapted to physical scales</li><li>Robust handling of edge cases (<span>$q \approx 1$</span>, <span>$\mu \approx 0$</span>)</li></ul><hr/><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><table><tr><th style="text-align: right">Feature</th><th style="text-align: right">Method</th><th style="text-align: right">Performance</th></tr><tr><td style="text-align: right">Growth factors D(z), f(z)</td><td style="text-align: right">ODE solve (Tsit5)</td><td style="text-align: right">~160-180 μs</td></tr><tr><td style="text-align: right">Multipole emulation</td><td style="text-align: right">Neural network</td><td style="text-align: right">~26 μs per multipole</td></tr><tr><td style="text-align: right">AP corrections</td><td style="text-align: right">Gauss-Lobatto quadrature</td><td style="text-align: right">~33 μs (3 multipoles)</td></tr><tr><td style="text-align: right">Interpolation</td><td style="text-align: right">Akima splines</td><td style="text-align: right">&lt;1 μs per evaluation</td></tr><tr><td style="text-align: right">Window convolution</td><td style="text-align: right">Tensor contraction</td><td style="text-align: right">Varies with kernel size</td></tr></table><p>All timings are approximate and depend on hardware (see Example page for system specifications).</p><hr/><h2 id="Further-Reading"><a class="docs-heading-anchor" href="#Further-Reading">Further Reading</a><a id="Further-Reading-1"></a><a class="docs-heading-anchor-permalink" href="#Further-Reading" title="Permalink"></a></h2><ul><li><strong>EFTofLSS theory</strong>: <a href="https://arxiv.org/abs/1004.2488">Baumann et al. 2012 (arXiv:1004.2488)</a></li><li><strong>EFTofLSS implementation</strong>: <a href="https://arxiv.org/abs/1909.05271">D&#39;Amico et al. 2020 (arXiv:1909.05271)</a></li><li><strong>Alcock-Paczynski effect</strong>: <a href="https://ui.adsabs.harvard.edu/abs/1979Natur.281..358A">Alcock &amp; Paczynski 1979</a></li><li><strong>Neural network emulation</strong>: <a href="https://arxiv.org/abs/1811.09504">Nishimichi et al. 2019 (arXiv:1811.09504)</a></li><li><strong>Window convolution</strong>: <a href="https://arxiv.org/abs/1810.05051">Beutler et al. 2019 (arXiv:1810.05051)</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../example/">« Example</a><a class="docs-footer-nextpage" href="../api_external/">External API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 24 November 2025 19:37">Monday 24 November 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
